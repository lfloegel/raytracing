monte carlo: gives statistical estimate of answer, and estimate gets increasingly accurate the longer it runs 
good for graphcis where great accuracy not needed 
ratio of circle area to square area: 
    pir^2 / (2r)^2 = pi/4 
    pi = 4 * (pir^2) /(2r)^2 
    pi = 4 * (N_inner / N_all) 
    r cancels out, r can be whatever value 
pi(): quickly get near pi, and then more slowly zero in on it 
    i.e. Law of Diminishing Returns: each sample helps less than the last 
    downside of mc 
    mitigate this diminishing by stratifying the samples 
    i.e. jittering 
        instead of taking random samples, take grid and take one sample within each 
        changes sample generation
        need to know how many samples taking in advance because need to know grid 
stratified method better 
    converges with better asymptopic rate 
    advantage decreases with dimension of problem 
    i.e. Curse of Dimensionality 
in book, high dimensional
    each reflection adds two dimensions
    no stratifying
    if doing single relfection or shadowing or strictly 2d problem, stratify 