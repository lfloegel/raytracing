integration in rendering 
    can do it for functions can't analytically integrate 
    i.e. lgo(sin(x))
in graphics, often have functions that can evaluate but can't write down explicity, or functions can only 
probabilistically evaluate 
    i.e. ray_color(): don't know what color is seen in every direction, but can statiscally estimate it any given
    dimesion 
problem with random program in previous books: small light sources create too much noise 
    uniform sampling doesn't sample these light sources often enough 
    light sources only sampled if ray scatters towards them 
        unlikely for small light sources, or far away light 
    could send more samples toward this light, but will cause scene to be inaccurately bright 
        remove inaccuracy by downweighting these samples to adjust for oversampling 
            need probability density function 
density function: ongoing form of histogram 
discrete density function: normalizes frequency y axis to a fraction or percentage 
    ongoing histogram where bins are infinite can't be fraction because heights of bins would drop to zero 
    density function: take bins and adjust them so they don't get shorter as more bins added 

probability density function: fractional histogram made infinite 
    can integrate region to figure out probability that r in some interval (x0,x1) 
        probability x0 < r < x1 = c * area(p(r),x0,x1) 
        c: scaling constant, =1 for cleanliness
        probability r has value 1 somewhere: 
            area(p(r),0,2) = 1 
p(r) proportional to r 
i.e. p = c' * r for some other constant c' 
    area(c'r, 0, 2) = 0 to 2 (c'r)dr = c'r^2 / 2 |r=0 to r=2 = c' * 2^2 / 2 - c' * 0^2 / 2 = 2c' 
    p(r) = r/2
given random number from d = random_double() that is uniform and between 0 and 1, should be able to get desired f(d) 
    suppose e = f(d) = d^2 
        no longer uniform pdf 
        pdf of e bigger near 0 than at it is near 1 
            squaring number between 0 and 1 makes it smaller 
        to convert general observation to function, need cdf P(x): 
            P(x) = area(p, -infinity, x) 
                for x where p(x) is not defined, p(x) = 0 
                i.e. probability of an x there is zero 
                cdf of pdf: 
                    P(x) = 0 : x < 0 
                    P(x) = x^2/4 : 0 < x < 2 
                    P(x) = 1 : x > 1 
            P(1.0) = 1/4: probability that random variable with the PDF is less than one is 25% 
                gives rise to clever observation that underlies many methods to generate non uniform random numbers 
                want function f() that when call it as f(random_double()) get return value with pdf x^2 / 4 
                if f() increasing, expect f(0.25) = 1.0 
                generalized: f(P(x)) = x 
                    P(x) percentage of x 
                    f(P(x)) percentage of that x 
                    f undos whatever P does: 
                        f(x) = P^-1(x) 
                        inverse function 
                e = P^-1(random)_double()) 
                for PDF p(x) = x/2 
                for P(x) compute inverse of P 
                    if y = x^2 / 4, get inverse by solving for x in terms of y: 
                        x = sqrt(4y) 
                random number with density p: 
                    e = sqrt(4 * random_double()) 
                    ranges from 0 to 2 
                    if replace random_double() with 1/4 get 1 as expected 

sample old sample: 2 * average(x^2, 0, 2) 
    need to account for non uniformity of pdf of x 
    where sample too much need to down weight 
    pdf perfect measure of how much or how little sampling being done 
        weighting function should be proportional to 1/pdf 

sampling more where integrand big 
    might expect less noise and thus faster convergence 
steering samples towards parts of distribution that are more important 
importance sampling: carefully choosing non uniform pdf 
take uniform samples so pdf = 1/2 over range [0,2] 
    can use machinery to get x = random_double(0,2) 
don't need 2 * sum / N anymore 
    handled by pdf 

underlays most mc ray tracers 
    1. have integral of f(x) over domain [a,b] 
    2. pick pdf p that is non zero over [a,b] 
    3. average a whole ton of f(r) / p(r) where r random number with pdf p 
any choice of pdf p always converges to righ answer, but closeer p approximates f, faster it converges 
